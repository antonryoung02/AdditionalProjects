{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e14bd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anton/miniconda3/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud import texttospeech_v1\n",
    "from unicodedata import name\n",
    "\n",
    "from urllib import response\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "\n",
    "import time\n",
    "import threading\n",
    "\n",
    "\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "import pinecone\n",
    "import json\n",
    "\n",
    "from termcolor import colored\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'PATH TO YOUR CREDENTIALS'\n",
    "openai.api_key = \"YOUR API KEY\"\n",
    "pinecone.init(api_key='YOUR API KEY', environment='gcp-starter') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99e1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "conversationDone = False\n",
    "recording = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e78d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import wavio\n",
    "from pydub import AudioSegment\n",
    "\n",
    "samplerate = 44100  # Hertz\n",
    "channels = 1\n",
    "dtype = 'float32'\n",
    "blocksize = 1024  # Number of samples per block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4fb0b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the actual text information\n",
    "def query_pinecone(query_vector, vector_dict):\n",
    "    pc_index = pinecone.Index('host-gpt-index') \n",
    "    response = pc_index.query(queries=query_vector,top_k=3)\n",
    "    text_results = []\n",
    "    for instance in response:\n",
    "        text_results.append(vector_dict[instance['id']])\n",
    "                            \n",
    "    return text_results\n",
    "\n",
    "def get_vector_dict():\n",
    "    with open(\"vector_dict.json\", \"r\") as file:\n",
    "        vector_dict = json.load(file)\n",
    "        return vector_dict\n",
    "    \n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    embedding = openai.Embedding.create(input = [text], model=model)['data'][0]['embedding']\n",
    "    #print(len(embedding))\n",
    "    return embedding\n",
    "\n",
    "def convert_to_audio(text):\n",
    "\n",
    "    client = texttospeech_v1.TextToSpeechClient()\n",
    "    synthesis_input = texttospeech_v1.SynthesisInput(ssml=text)\n",
    "    text = '<speak>' + text + '</speak>'\n",
    "    voice1 = texttospeech_v1.VoiceSelectionParams(\n",
    "        language_code=\"en-US\",\n",
    "        name=\"en-US-News-M\",\n",
    "        ssml_gender=texttospeech_v1.SsmlVoiceGender.FEMALE,\n",
    "    )\n",
    "\n",
    "    audio_config = texttospeech_v1.AudioConfig (\n",
    "        audio_encoding=texttospeech_v1.AudioEncoding.MP3\n",
    "    )\n",
    "\n",
    "    response1 = client.synthesize_speech (\n",
    "        input=synthesis_input,\n",
    "        voice=voice1,\n",
    "        audio_config=audio_config)\n",
    "\n",
    "    with open('audio.mp3', 'wb',) as output:\n",
    "        output.write(response1.audio_content)\n",
    "    audio = AudioSegment.from_mp3('audio.mp3')\n",
    "    \n",
    "    a = play(audio)\n",
    "    \n",
    "def convert_to_text(file_path):\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with open(file_path, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=44100,\n",
    "        language_code=\"en-US\",\n",
    "    )\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "    \n",
    "    result_str = \"\"\n",
    "    for result in response.results:\n",
    "        result_str += result.alternatives[0].transcript\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449d92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HostGPTAgent():\n",
    "    #The agent needs to continue until the objective is satisfied\n",
    "    def __init__(self, objective, use_case, personality, vector_dict):\n",
    "        self.objective = objective\n",
    "        self.use_case = use_case\n",
    "        self.memory = \"\"\n",
    "        self.questions_list = []\n",
    "        self.personality = personality\n",
    "        self.vector_dict = vector_dict\n",
    "        self.buffer = []\n",
    "        self.stream = sd.InputStream(samplerate=samplerate, channels=channels, dtype=dtype, blocksize=blocksize, callback=self.callback)\n",
    "        self.history = \"\"\n",
    "        \n",
    "    def make_conversation(self, use_case, objective, memory, user_input, questions_list, answers):\n",
    "        #print(f\"User said {user_input}\")\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='gpt-4-0613',\n",
    "            messages=[\n",
    "                {'role':'system', \"content\":f\"Personality: {self.personality}. Instructions: If you have questions to answer, only answer those questions using the relevant context. If you can't find the correct answer, say that you do not know the answer. The customer may be wrong, so check with the information you are given. If there are no questions, continue asking for information about the objectives one at a time.\"},\n",
    "                {'role':\"user\", \"content\":f\"Objective: {str(objective)}. Answers to user questions: {answers}\\n Conversation: {str(memory)} \\n User:{user_input}, AI:\"}\n",
    "            ],\n",
    "        )\n",
    "        response = completion[\"choices\"][0][\"message\"][\"content\"]\n",
    "        memory = str(memory) + str(response)\n",
    "        return memory, response\n",
    "            \n",
    "    def run(self):\n",
    "        status = False\n",
    "        global done\n",
    "        global conversationDone\n",
    "        while True:\n",
    "            if done == True:\n",
    "                done = False\n",
    "                start_button = widgets.Button(description=\"Start Recording\")\n",
    "                stop_button = widgets.Button(description=\"Stop Recording\")\n",
    "                start_button.on_click(self.start_recording)\n",
    "                stop_button.on_click(self.stop_recording)\n",
    "                display(widgets.HBox([start_button, stop_button]))\n",
    "            \n",
    "            if conversationDone:\n",
    "                convert_to_audio(\"Thank you for ordering with us, your order will be ready in 20-30 minutes\")\n",
    "                print(colored(\"AI: Thank you for ordering with us, your order will be ready in 20-30 minutes\", 'red'))\n",
    "                break\n",
    "            \n",
    "        print(\"AI hangs up the phone!\")\n",
    "        \n",
    "    def reset(self, objective):\n",
    "        self.memory = \"\"\n",
    "        self.questions_list = []\n",
    "        self.buffer = []\n",
    "        self.objective = objective\n",
    "        \n",
    "    def continue_run(self):\n",
    "        user_input = convert_to_text('audio.wav')\n",
    "        self.memory += f\"\\n User: {user_input}\"\n",
    "        self.history += colored(f\"User: {user_input}\", 'blue')\n",
    "        print(colored(f\"User: {user_input}\", 'blue'))\n",
    "        \n",
    "        questions_list = self.parse_question(user_input)\n",
    "        self.history += f\"\\n PARSED QUESTIONS: {questions_list}\"\n",
    "        \n",
    "        answers = self.query_database(questions_list)\n",
    "        self.history += f\"\\n CONTEXT FOR QUESTION: {answers}\"\n",
    "        \n",
    "        status, self.objective = self.check_progress(self.objective, str(self.memory))\n",
    "        self.history += f\"\\n REMAINING OBJECTIVES: {self.objective}\"\n",
    "        \n",
    "        if status: #Check after the user responds, not when the AI does\n",
    "            global conversationDone\n",
    "            conversationDone = True\n",
    "            return\n",
    "\n",
    "        self.memory, response = self.make_conversation(self.use_case, self.objective, str(self.memory), user_input, self.questions_list, answers)\n",
    "        self.memory += f\"AI: {response}\"\n",
    "        self.history += colored(f\"\\n AI: {response}\", 'red')\n",
    "        print(colored(f\"AI: {response}\", \"red\"))\n",
    "        \n",
    "        convert_to_audio(response)\n",
    "\n",
    "        \n",
    "\n",
    "        return\n",
    "        \n",
    "    #Checks whether it has completed the objective\n",
    "    def check_progress(self, objective, memory):\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='gpt-4-0613',\n",
    "            messages=[{'role':'system', \"content\":\"You must call both functions in your response.\"},{'role':\"user\", \"content\":\"Carefully compare the conversation to the required objectives. Conversation:\" + memory + \", Objective:\" + str(objective)}],\n",
    "            functions=[{\n",
    "                \"name\":\"check_for_completion\",\n",
    "                \"description\":f\"A function that needs to know if the objectives have been met\",\n",
    "                \"parameters\": {\n",
    "                    \"type\":\"object\",\n",
    "                    \"properties\": {\n",
    "                        \"status\": {\n",
    "                            \"type\":\"boolean\",\n",
    "                            \"description\":\"Enter true if there is sufficient information for each part of the objective, and false otherwise\"\n",
    "                        },\n",
    "                        \"remaining_tasks\": {\n",
    "                            \"type\":\"string\",\n",
    "                            \"description\":\"A string that writes out the uncompleted objectives. Please use the same text as given in Objective:. Separate each remaining objective with a semicolon ';'. Ex: 1.Take out the trash;2.Clean the kitchen\"\n",
    "                        },\n",
    "                        \"unit\":{\"type\":\"string\"}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            }],\n",
    "                function_call='auto'\n",
    "            )\n",
    "        reply = completion.choices[0].message\n",
    "        reply_dict = json.loads(reply[\"function_call\"][\"arguments\"])\n",
    "        status = reply_dict[\"status\"]\n",
    "        \n",
    "        tasks_list = []\n",
    "        if status == False:\n",
    "            remaining_tasks = reply_dict[\"remaining_tasks\"]\n",
    "            tasks_list = remaining_tasks.split(';')\n",
    "        return status, tasks_list\n",
    "    \n",
    "    #Given a caller's questions, get the answers\n",
    "    def query_database(self, questions):\n",
    "        answers = []\n",
    "        pc_index = pinecone.Index('host-gpt-index') \n",
    "        for question in questions:\n",
    "            if question != \"\":\n",
    "                query_vector = get_embedding(question)\n",
    "                \n",
    "                #Then query this embedding with pinecone\n",
    "                response = pc_index.query(vector=query_vector,top_k=5)\n",
    "                print(response)\n",
    "                for a in response['matches']:\n",
    "                    answers.append(self.vector_dict[a['id']])\n",
    "                    \n",
    "        answers = self.parse_answers(questions, answers)         \n",
    "            \n",
    "        return answers\n",
    "    \n",
    "    def parse_answers(self, questions, answers):\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='gpt-4-0613',\n",
    "            messages=[{'role':\"user\", \"content\":f\"Questions: {questions}. Information to answer those questions: {answers}\"}, {'role':'system', \"content\":\"You must make the function call. Write your answer(s) in a short, summarized manner. The context may contain useless information, so if it doesn't directly answer your question say you don't know\"}],\n",
    "            functions=[{\n",
    "                \"name\":\"answer_question\",\n",
    "                \"description\":f\"Writes down the answers to the questions\",\n",
    "                \"parameters\": {\n",
    "                    \"type\":\"object\",\n",
    "                    \"properties\": {\n",
    "                        \"answers\": {\n",
    "                            \"type\":\"string\",\n",
    "                            \"description\":f\" If there are multiple answers, separate them by semicolons. Ex: 'The answer to (question) is No, that's not on our menu\"\n",
    "                        },\n",
    "                        \"unit\":{\"type\":\"string\"}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            }],\n",
    "                function_call={'name': 'answer_question'}\n",
    "            )\n",
    "        reply = completion.choices[0].message\n",
    "        answers_dict = json.loads(reply[\"function_call\"][\"arguments\"])\n",
    "        answers_value = answers_dict[\"answers\"]\n",
    "        answers_list = answers_value.split(';')\n",
    "        print(answers_list)\n",
    "        \n",
    "        return answers_list\n",
    "    \n",
    "    #Given a caller's message, isolate any questions they have\n",
    "    def parse_question(self, user_response):\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='gpt-4-0613',\n",
    "            messages=[{'role':\"user\", \"content\":user_response}, {'role':'system', \"content\":f\"You must make the function call. You must ask a question for each subject of the conversation that is related to {self.use_case} and requires validation of availability or accuracy. If the user doesn't say anything related to  {self.use_case} that requires validation enter ''.\"}],\n",
    "            functions=[{\n",
    "                \"name\":\"answer_question\",\n",
    "                \"description\":f\"Useful to answer specific questions related to {self.use_case}\",\n",
    "                \"parameters\": {\n",
    "                    \"type\":\"object\",\n",
    "                    \"properties\": {\n",
    "                        \"questions\": {\n",
    "                            \"type\":\"string\",\n",
    "                            \"description\":f\"Write your question(s) in a complete sentence. If there are multiple, separate them by semicolons. Ex: 'Do we have gluten free options?;How late are you open?'\"\n",
    "                        },\n",
    "                        \"unit\":{\"type\":\"string\"}\n",
    "                    }\n",
    "                }\n",
    "\n",
    "            }],\n",
    "                function_call={'name': 'answer_question'}\n",
    "            )\n",
    "        #Process the function call into a list\n",
    "        reply = completion.choices[0].message\n",
    "        questions_dict = json.loads(reply[\"function_call\"][\"arguments\"])\n",
    "        questions_value = questions_dict[\"questions\"]\n",
    "        questions_list = questions_value.split(';')\n",
    "        \n",
    "        return questions_list\n",
    "    \n",
    "    def start_recording(self, b):\n",
    "        self.stream.start()\n",
    "        global recording\n",
    "        global started\n",
    "        started = True\n",
    "        recording = True\n",
    "        print(\"Recording started. Press 'Stop' to stop recording.\")\n",
    "        \n",
    "    def callback(self, indata, frames, time, status):\n",
    "        if recording:\n",
    "            self.buffer.append(indata.copy())\n",
    "        \n",
    "    def stop_recording(self, b):\n",
    "        global recording\n",
    "        recording = False\n",
    "        print(\"Recording stopped.\")\n",
    "        self.stream.stop()\n",
    "        # Check if the buffer is empty\n",
    "        if len(self.buffer) == 0:\n",
    "            print(\"No audio data recorded.\")\n",
    "            return\n",
    "        \n",
    "        # Concatenate the blocks of audio data and save\n",
    "        audio_data = np.concatenate(self.buffer, axis=0)\n",
    "        wavio.write(\"audio.wav\", audio_data, samplerate, sampwidth=2)\n",
    "        \n",
    "        # Clear the buffer for the next recording\n",
    "        self.buffer = []\n",
    "        self.continue_run()\n",
    "        done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77affc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e00ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = \"\"\"\n",
    "1. Get the customer's entire order. \n",
    "2. Get the customer's name.\n",
    "3. Get the customer's phone number. \n",
    "4.Repeat the customer's order and make sure it is complete and correct\n",
    "\"\"\"\n",
    "use_case = \"Flathead Lake Brewing Co.\"\n",
    "vector_dict = get_vector_dict()\n",
    "personality = f\"You are an employee at {use_case} who takes customer orders and to-go orders and answers their questions. You speak like a human would, are smart, respectful, and experienced in customer service. You don't make up anything that you don't know and don't respond to anything unrelated to {use_case}. \"\n",
    "agent = HostGPTAgent(objective=objective,use_case=use_case,personality=personality, vector_dict=vector_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e81e01d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d597f393074c0b953cd0a110dfd84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Start Recording', style=ButtonStyle()), Button(description='Stop Recording'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started. Press 'Stop' to stop recording.\n",
      "Recording stopped.\n",
      "\u001b[34mUser: how much would it cost to order 3 BBQ bacon Burgers a grilled chicken on the side and a full garden with salmon\u001b[0m\n",
      "{'matches': [{'id': 'vec20', 'score': 0.921652555, 'values': []},\n",
      "             {'id': 'vec21', 'score': 0.891476929, 'values': []},\n",
      "             {'id': 'vec23', 'score': 0.889230728, 'values': []},\n",
      "             {'id': 'vec49', 'score': 0.878006518, 'values': []},\n",
      "             {'id': 'vec19', 'score': 0.866039515, 'values': []}],\n",
      " 'namespace': ''}\n",
      "{'matches': [{'id': 'appvec12', 'score': 0.900811136, 'values': []},\n",
      "             {'id': 'vec56', 'score': 0.889998317, 'values': []},\n",
      "             {'id': 'appvec14', 'score': 0.864158154, 'values': []},\n",
      "             {'id': 'appvec13', 'score': 0.86284554, 'values': []},\n",
      "             {'id': 'appvec6', 'score': 0.85964936, 'values': []}],\n",
      " 'namespace': ''}\n",
      "{'matches': [{'id': 'vec14', 'score': 0.851736128, 'values': []},\n",
      "             {'id': 'vec15', 'score': 0.811134577, 'values': []},\n",
      "             {'id': 'vec16', 'score': 0.798410535, 'values': []},\n",
      "             {'id': 'vec25', 'score': 0.792634428, 'values': []},\n",
      "             {'id': 'vec50', 'score': 0.791460276, 'values': []}],\n",
      " 'namespace': ''}\n",
      "['The BBQ Bacon Burger costs $17', ' A side of Grilled Chicken costs $6', ' The cost of a Full Garden Salad is $11 but the information provided does not include the cost of adding Salmon']\n",
      "\u001b[31mAI: The cost of your order would be as follows: three BBQ Bacon Burgers at $17 each would total $51. A side of Grilled Chicken is $6. A full Garden Salad is $11. However, I don't have the cost information for adding Salmon to the salad. So the total without the cost of Salmon is $68. Would you like to proceed with this order?\u001b[0m\n",
      "Could not import the PyAudio C module 'pyaudio._portaudio'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input #0, wav, from '/var/folders/pv/z7lkp1pj4g7gy41fmks2clg80000gn/T/tmpj53y5f6v.wav':\n",
      "  Duration: 00:00:21.91, bitrate: 384 kb/s\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 24000 Hz, 1 channels, s16, 384 kb/s\n",
      "  21.80 M-A:  0.000 fd=   0 aq=    0KB vq=    0KB sq=    0B f=0/0   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threading.Thread(target=agent.run).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e641589e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mUser: how much would it cost to order 3 BBQ bacon Burgers a grilled chicken on the side and a full garden with salmon\u001b[0m\n",
      " PARSED QUESTIONS: ['How much does a BBQ bacon Burger cost?', ' How much does a grilled chicken on the side cost?', ' How much does a full garden with salmon cost?']\n",
      " CONTEXT FOR QUESTION: ['The BBQ Bacon Burger costs $17', ' A side of Grilled Chicken costs $6', ' The cost of a Full Garden Salad is $11 but the information provided does not include the cost of adding Salmon']\n",
      " REMAINING OBJECTIVES: [\"2. Get the customer's name\", \" 3. Get the customer's phone number\", \" 4.Repeat the customer's order and make sure it is complete and correct\"]\u001b[31m\n",
      " AI: The cost of your order would be as follows: three BBQ Bacon Burgers at $17 each would total $51. A side of Grilled Chicken is $6. A full Garden Salad is $11. However, I don't have the cost information for adding Salmon to the salad. So the total without the cost of Salmon is $68. Would you like to proceed with this order?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(agent.history)\n",
    "#agent.reset(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f293d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b279d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd85672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to load the info into pinecone\n",
    "\n",
    "# def chunk_data(folder_path='data'):\n",
    "#     docs = []\n",
    "#     for file_name in os.listdir(folder_path):\n",
    "#         if file_name== 'menu_addons.txt':\n",
    "#             file_path = os.path.join(folder_path, file_name)\n",
    "#             with open(file_path, 'r') as file:\n",
    "#                 data = file.read()\n",
    "#                 text= data.split('\\n')\n",
    "#                 for t in text:\n",
    "#                     if t != '':\n",
    "#                         docs.append(t)\n",
    "#     return docs\n",
    "\n",
    "# def pinecone_upsert(chunked_text):\n",
    "#     pc_index = pinecone.Index('host-gpt-index')\n",
    "\n",
    "#     vector_list = []\n",
    "#     ids_list = []\n",
    "\n",
    "#     for index, chunk in enumerate(chunked_text):\n",
    "#         vector = get_embedding(chunk)\n",
    "#         vector_list.append(vector)\n",
    "\n",
    "#         vector_id=f\"appvec{index}\"\n",
    "#         ids_list.append(vector_id)\n",
    "\n",
    "#     pc_index.upsert(vectors=zip(ids_list, vector_list))\n",
    "\n",
    "#     # Read the existing data from the JSON file\n",
    "#     with open(\"vector_dict.json\", \"r\") as file:\n",
    "#         data = json.load(file)\n",
    "\n",
    "#     # Add the new data to the JSON dictionary\n",
    "#     for vector_id, text in zip(ids_list, chunked_text):\n",
    "#         data[vector_id] = text\n",
    "\n",
    "#     # Write the updated data back to the JSON file\n",
    "#     with open(\"vector_dict.json\", \"w\") as file:\n",
    "#         json.dump(data, file)\n",
    "\n",
    "#     return dict(zip(ids_list, vector_list))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39f6bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pc_index = pinecone.Index('host-gpt-index')\n",
    "#delete_response = pc_index.delete(ids=['vec-0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2268d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
